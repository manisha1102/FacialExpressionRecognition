{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "591_CmGY3AeJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_szUQYg43EPc"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PIoch0R73wNk"
   },
   "outputs": [],
   "source": [
    "def getData(balance_ones = True , Ntest= 1000):\n",
    "  X =[]\n",
    "  Y =[]\n",
    "  first = True\n",
    "  for line in open('fer/fer2013.csv'):\n",
    "    if first:\n",
    "      first = False\n",
    "    else:\n",
    "      row = line.split(',')\n",
    "      Y.append(int(row[0]))\n",
    "      X.append([int(p) for p in row[1].split()])\n",
    "  \n",
    "  X,Y = np.array(X)/255.0 , np.array(Y)\n",
    "  X , Y = shuffle(X,Y)\n",
    "  Xtrain , Ytrain = X[:-Ntest] , Y[:-Ntest]\n",
    "  Xvalid , Yvalid = X[-Ntest:] , Y[-Ntest:]\n",
    "  if balance_ones:\n",
    "    X0,Y0 = Xtrain[Ytrain!=1, :] , Ytrain[Ytrain!=1]\n",
    "    X1 = Xtrain[Ytrain==1, :]\n",
    "    X1 = np.repeat(X1 , 9 , axis=0)\n",
    "    Xtrain = np.vstack([X0,X1])\n",
    "    Ytrain = np.concatenate((Y0 , [1]*len(X1)))\n",
    "    return Xtrain , Ytrain , Xvalid , Yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F_2FfeKT35DB"
   },
   "outputs": [],
   "source": [
    "def getImageData():\n",
    "  Xtrain , Ytrain , Xvalid , Yvalid = getData()\n",
    "  N,D = Xtrain.shape\n",
    "  d = int(np.sqrt(D))\n",
    "  Xtrain = Xtrain.reshape(-1,d,d,1)\n",
    "  Xvalid = Xvalid.reshape(-1,d,d,1)\n",
    "  return Xtrain , Ytrain , Xvalid , Yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bKCucmsO5JAS"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(48, 48, 1)),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(7, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhxVrrv36jZB",
    "outputId": "822d38c9-dfc1-4f61-ab8c-476bc5050753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 46, 46, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 23, 23, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 21, 21, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 551,687\n",
      "Trainable params: 551,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_9GumoHV60lB"
   },
   "outputs": [],
   "source": [
    "Xtrain , Ytrain , Xvalid , Yvalid = getImageData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "81f6j2hS7cM5"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hG9qIIN8rTx",
    "outputId": "3cf24d5a-97be-44a9-84a0-3ca0d2dbb677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 1.5866 - accuracy: 0.3883\n",
      "Epoch 2/15\n",
      "1223/1223 [==============================] - 38s 31ms/step - loss: 1.2158 - accuracy: 0.5431\n",
      "Epoch 3/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 1.0531 - accuracy: 0.6023\n",
      "Epoch 4/15\n",
      "1223/1223 [==============================] - 42s 35ms/step - loss: 0.9533 - accuracy: 0.6400\n",
      "Epoch 5/15\n",
      "1223/1223 [==============================] - 41s 34ms/step - loss: 0.8738 - accuracy: 0.6718\n",
      "Epoch 6/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 0.7927 - accuracy: 0.7034\n",
      "Epoch 7/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 0.7101 - accuracy: 0.7367\n",
      "Epoch 8/15\n",
      "1223/1223 [==============================] - 41s 34ms/step - loss: 0.6187 - accuracy: 0.7707\n",
      "Epoch 9/15\n",
      "1223/1223 [==============================] - 40s 32ms/step - loss: 0.5313 - accuracy: 0.8060\n",
      "Epoch 10/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 0.4410 - accuracy: 0.8407\n",
      "Epoch 11/15\n",
      "1223/1223 [==============================] - 41s 33ms/step - loss: 0.3626 - accuracy: 0.8709\n",
      "Epoch 12/15\n",
      "1223/1223 [==============================] - 39s 32ms/step - loss: 0.2915 - accuracy: 0.8983\n",
      "Epoch 13/15\n",
      "1223/1223 [==============================] - 40s 33ms/step - loss: 0.2391 - accuracy: 0.9171\n",
      "Epoch 14/15\n",
      "1223/1223 [==============================] - 45s 36ms/step - loss: 0.1977 - accuracy: 0.9321\n",
      "Epoch 15/15\n",
      "1223/1223 [==============================] - 40s 32ms/step - loss: 0.1766 - accuracy: 0.9399\n"
     ]
    }
   ],
   "source": [
    "modl = model.fit(x=Xtrain, y=Ytrain, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q4gNmbN081YO"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('D:/Downloads/human.jfif')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.5428565e-06 5.5642408e-17 8.2551114e-02 3.1081965e-04 1.0431643e-03\n",
      " 4.5314507e-04 9.1563714e-01]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "gray = cv2.resize(gray, (48,48))\n",
    "x = image.img_to_array(gray)\n",
    "x = x/255\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=10)\n",
    "print(classes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Facial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
